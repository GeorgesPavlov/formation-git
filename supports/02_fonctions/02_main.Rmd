---
title: "Tirer profit des fonctions en `R`"
author: "Lino Galiana"
date: "13 mai 2019"
output:
  html_document:
    css: ../style.css
    toc: true
    toc_float: true
    code_folding: show
    number_sections: true
---

<script src="../js/hideOutput.js"></script>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


> To understand computations in R, two slogans are helpful:
>
>  * Everything that exists is an object.
>  * Everything that happens is a function call.
>
> *John Chambers*


 
`R` est, dans son essence, un langage de programmation fonctionnelle. L'utilisation de fonctions est ainsi la manière privilégiée de développer un programme en `R`: comprendre la manière dont elles fonctionnent, interagissent avec l'environnement de l'utilisateur, est la meilleure manière de développer, par la suite, un programme reproductible. 

Construire un *workflow* à partir de fonctions est une pratique qui permet de réduire les risques de *bug* (en identifiant mieux leur origine) et, surtout, assure un code plus flexible et reproductible. Cela renvoie au paradigme informatique du *“do not repeat yourself”*.

Popularised by the “pragmatic programmers”, Dave Thomas and Andy Hunt, this principle states:

> “Every piece of knowledge must have a single, unambiguous, authoritative representation within a system”
>
> Dave Thomas and Andy Hunt, *The Pragmatic Programmer*

Cette approche nous intéresse particulièrement car elle rend le code plus clair, plus robuste, plus facile à répliquer et à faire évoluer.



# Créer des fonctions

## Fonctions avec un seul argument

Supposons qu'on ait chargé une base de données qui utilise le code `−99` pour représenter les valeurs manquantes. On désire remplacer l'ensemble des `−99` par des `NA`s.

```{r}
# On fixe la racine pour être sûr de tous avoir le même dataset
set.seed(1014)

# On créé un dataframe
df <- data.frame(replicate(6, sample(c(1:10, -99), 6, rep = TRUE)))
names(df) <- letters[1:6]
df
```

Un premier jet de code pourrait prendre la forme suivante:

```{r}
df2 <- df
df2$a[df2$a == -99] <- NA
df2$b[df2$b == -99] <- NA
df2$c[df2$c == -99] <- NA
df2$d[df2$d == -99] <- NA
df2$e[df2$e == -98] <- NA
df2$f[df2$g == -99] <- NA
df2
```

Quelque chose ne vous choque pas ? Regardez précisément le code et le dataframe (indice: surveillez la colonne `e`)

On a introduit une erreur humaine dans le code, difficile à détecter. La tâche ici est identique entre les colonnes, on a envie de mettre en place une structure générale, qu'on appliquerait *n* fois, qui éviterait ce problème (quitte à avoir une erreur, mieux vaut s'en rendre compte en la faisant systématiquement). 

Construire une fonction est simple en `R` et emboîter ou enchaîner des fonctions également. Cela prend la forme suivante
```{r, eval = FALSE}
nom_fonction <- function(arg1,arg2,...,argK){
  
  # fait qqch
  # -----
  
  # Retourne resultat
  return(mon_output)
}
```

Pour généraliser le code précédent, on voit qu'il y a une structure commune à toutes nos lignes de la forme `.[. == -99] <- NA`: cela servira de base à notre fonction. 

Ecrivez un exemple de fonction `fix_missing` qui généralise, simplement, ce travail de nettoyage. Elle prendra en entrée x (un vecteur) et retourne ce vecteur avec les valeurs manquantes corrigées

<div class="fold o s">
```{r}
fix_missing <- function(x) {
  x[x == -99] <- NA
  x
}
```
</div>

On peut l'appliquer avec le code suivant:
```{r}
df2 <- df
df2$a <- fix_missing(df2$a)
df2$b <- fix_missing(df2$b)
df2$c <- fix_missing(df2$c)
df2$d <- fix_missing(df2$d)
df2$e <- fix_missing(df2$e)
df2$f <- fix_missing(df2$f)
df2

# On va comparer au resultat donc on le garde
df2_good <- df2
```

C'est mieux (on ne fait plus l'erreur précédente), mais cela n'élimine pas encore toute possibilité d'erreur: il n'est plus possible de taper `-98` au lieu de `-99`, mais il est toujours possible de se tromper dans le nom des variables
```{r}
df2 <- df
# On se trompe à nouveau
df2$a <- fix_missing(df2$a)
df2$b <- fix_missing(df2$b)
df2$c <- fix_missing(df2$c)
df2$d <- fix_missing(df2$d)
df2$d <- fix_missing(df2$d)
df2$f <- fix_missing(df2$e)
df2
```
par exemple, l'erreur typographique ci-dessus reste vicieuse. La prochaine étape est ainsi d'éliminer ce risque d'erreur en combinant deux fonctions (ce qu'on appelle combinaison de fonctions). La première `fix_missing()` sert à régler le problème sur un vecteur. La seconde généralisera ce procédé à toutes les colonnes. Comme `R` est un langage vectoriel, c'est une approche fréquente de construire des fonctions sur des vecteurs et les appliquer ensuite à plusieurs colonnes.

La famille des fonctions `apply` est conçue pour appliquer une même fonction à plusieurs objets. La plus puissante, celle qu'il faut normalement utiliser, est la fonction `lapply` qui permet de stocker le résultat sous forme de liste. Celle-ci est à préférer à la fonction `sapply` qui effectue des conversions de type de données, ce qui peut être dangereux. Un peu plus bas, vous trouverez une approche alternative qui évite le `lapply` mais qui implique d'utiliser le package `reshape2`. Comme `R` est un langage vectoriel, de manière générale, les *dataframes* sous format *long* sont plus maniables que les *dataframes* sous format *wide* lorsqu'on veut leur imposer des opérations vectorielles

`lapply()` est ce qu'on appelle une *fonctionnelle* car elle prend une fonction comme argument. Les dataframes étant en fait des listes, `lapply` s'applique. On a juste besoin d'une petite astuce pour s'assurer que la sortie de la fonction soit bien un *dataframe* et non une liste. A la place d'assigner le résultat sous la forme `df <- lapply(.....)` on va faire `df[] <- lapply(.....)`.

fix_missing <- function(x) {
  x[x == -99] <- NA
  x
}
df[] <- lapply(df, fix_missing)


This code has five advantages over copy and paste:

    It’s more compact.

    If the code for a missing value changes, it only needs to be updated in one place.

    It works for any number of columns. There is no way to accidentally miss a column.

    There is no way to accidentally treat one column differently than another.

    It is easy to generalise this technique to a subset of columns:

    df[1:5] <- lapply(df[1:5], fix_missing)

The key idea is function composition. Take two simple functions, one which does something to every column and one which fixes missing values, and combine them to fix missing values in every column. Writing simple functions that can be understood in isolation and then composed is a powerful technique.

What if different columns used different codes for missing values? In this case, you could argue that we should just add another argument:

fix_missing <- function(x, na.value) {
  x[x == na.value] <- NA
  x
}


Il y aurait une manière encore plus intelligente de traiter ce problème évitant d'appliquer la fonction `lapply`. En transformant le format du *dataframe* de *wide* (beaucoup de colonnes) en *long* (beaucoup de lignes), on évite le *lapply*. 
```{r}
#' Version alternative du programme évitant une boucle \code{lapply}
#' 
#' @param df Dataframe
#' @return \code{df} avec les valeurs manquantes transformées

fix_missing_long <- function(df){
  
  # On transforme les données au format 'long'
  df2 <- reshape2::melt(df)
  
  # On applique la transformation au vecteur de 'valeurs'
  df2$value <- fix_missing(df2$value)
  
  # On utilise une fonction de 'base' pour numéroter les lignes par variable
  df2$id <- ave(df2$val, df2$variable, FUN = seq_along)
  
  # On revient au format 'wide' initial
  df2 <- reshape2::dcast(df2, id~variable, value.var = "value")[,-1]
  
  return(df2)
}

fix_missing_long(df)

identical(fix_missing_long(df),df2_good)
# blable
```


### Closures

Closures get their name because they enclose the environment of the parent function and can access all its variables. This is useful because it allows us to have two levels of parameters: a parent level that controls operation and a child level that does the work.

# Documenter des fonctions



# Noms et valeurs

In R, it is important to understand the distinction between an object and its name.

```{r}
x <- c(1, 2, 3)
```

On serait tenté de lire "je crée un objet appelé 'x' contenant les valeurs 1,2 et 3". En réalité, R procède de la manière suivante:

* `R` crée un vecteur de valeurs `c(1, 2, 3)`
* `R` lie (*binds*) ce vecteur a un nom, ici `x`

Autrement dit, l'objet/la valeur n'a pas de nom ; c'est le nom qui a une valeur. L'opérateur  assignation `<-` crée donc un lien entre un nom et une valeur. Un nom est une référence à une valeur: cela évite que le code ci-dessous

```{r}
y <- x
```

crée une copie d'un objet déjà existant (`x`). Ce qu'il fait, c'est créer une référence supplémentaire pour accéder au vecteur `c(1,2,3)`

## Copie

Le code ci-dessous lie `x` à `y` puis modifie `y`:
```{r}
x <- c(1, 2, 3)
y <- x

y[[3]] <- 4
x
```

Cela ne modifie pas `x`. Alors que la valeur associée à *y* a changé, l'objet original n'a pas changé. A la place, `R` a créé un nouvel objet. 

Ce comportement est appelé **copy-on-modify**. C'est parce que les objets R sont, en principe, immutables et que, ainsi, les faire évoluer implique de modifier la valeur sous-jacente. 

```{r}
f <- function(a) {
  a
}

x <- c(1,2,3)
f(x)
```

While f() is running, the a inside the function points to the same value as the x does outside the function


Functions can be broken down into three components: arguments, body, and environment.

Functions are objects, just as vectors are objects.

## Function components

A function has three parts:

* The formals(), the list of arguments that control how you call the function.
* The body(), the code inside the function.
* The environment(), the data structure that determines how the function finds the values associated with the names.

While the formals and body are specified explicitly when you create a function, the environment is specified implicitly, based on where you defined the function. The function environment always exists, but it is only printed when the function isn’t defined in the global environment.

```{r}
f02 <- function(x, y) {
  # A comment
  x + y
}

formals(f02)
#> $x
#> 
#> 
#> $y

body(f02)
#> {
#>     x + y
#> }

environment(f02)
#> <environment: R_GlobalEnv>
```


While you almost always create a function and then bind it to a name, the binding step is not compulsory. If you choose not to give a function a name, you get an anonymous function. This is useful when it’s not worth the effort to figure out a name:

lapply(mtcars, function(x) length(unique(x)))
Filter(function(x) !is.numeric(x), mtcars)
integrate(function(x) sin(x) ^ 2, 0, pi)

A final option is to put functions in a list:

funs <- list(
  half = function(x) x / 2,
  double = function(x) x * 2
)

funs$double(10)
#> [1] 20

In R, you’ll often see functions called closures. This name reflects the fact that R functions capture, or enclose, their environments

In Chapter 2, we discussed assignment, the act of binding a name to a value. Here we’ll discuss scoping, the act of finding the value associated with a name.

The basic rules of scoping are quite intuitive, and you’ve probably already internalised them, even if you never explicitly studied them. For example, what will the following code return, 10 or 20?25

x <- 10
g01 <- function() {
  x <- 20
  x
}

g01()

In this section, you’ll learn the formal rules of scoping as well as some of its more subtle details. A deeper understanding of scoping will help you to use more advanced functional programming tools, and eventually, even to write tools that translate R code into other languages.

R uses lexical scoping26: it looks up the values of names based on how a function is defined, not how it is called. “Lexical” here is not the English adjective that means relating to words or a vocabulary. It’s a technical CS term that tells us that the scoping rules use a parse-time, rather than a run-time structure.

R’s lexical scoping follows four primary rules:

    Name masking
    Functions versus variables
    A fresh start
    Dynamic lookup


## Name masking

The basic principle of lexical scoping is that names defined inside a function mask names defined outside a function. This is illustrated in the following example.

```{r}
x <- 10
y <- 20
g02 <- function() {
  x <- 1
  y <- 2
  c(x, y)
}
g02()
```


If a name isn’t defined inside a function, R looks one level up.


```{r}
x <- 2
g03 <- function() {
  y <- 1
  c(x, y)
}
g03()
#> [1] 2 1

# And this doesn't change the previous value of y
y
#> [1] 20
```

The same rules apply if a function is defined inside another function. First, R looks inside the current function. Then, it looks where that function was defined (and so on, all the way up to the global environment). Finally, it looks in other loaded packages.

g11 <- function() {
  if (!exists("a")) {
    a <- 1
  } else {
    a <- a + 1
  }
  a
}

g11()
g11()

You might be surprised that g11() always returns the same value. This happens because every time a function is called a new environment is created to host its execution. This means that a function has no way to tell what happened the last time it was run; each invocation is completely independent. 


#### Dynamic lookup

Lexical scoping determines where, but not when to look for values. R looks for values when the function is run, not when the function is created. Together, these two properties tell us that the output of a function can differ depending on the objects outside the function’s environment:

g12 <- function() x + 1
x <- 15
g12()
#> [1] 16

x <- 20
g12()
#> [1] 21

This behaviour can be quite annoying. If you make a spelling mistake in your code, you won’t get an error message when you create the function. And depending on the variables defined in the global environment, you might not even get an error message when you run the function.

To detect this problem, use codetools::findGlobals(). This function lists all the external dependencies (unbound symbols) within a function:

codetools::findGlobals(g12)
#> [1] "+" "x"


### Lazy evaluation

In R, function arguments are lazily evaluated: they’re only evaluated if accessed. For example, this code doesn’t generate an error because x is never used:

h01 <- function(x) {
  10
}
h01(stop("This is an error!"))
#> [1] 10

This is an important feature because it allows you to do things like include potentially expensive computations in function arguments that will only be evaluated if needed.

Lazy evaluation is powered by a data structure called a promise


 promise has three components:

    An expression, like x + y, which gives rise to the delayed computation.

    An environment where the expression should be evaluated, i.e. the environment where the function is called
    

  A value, which is computed and cached the first time a promise is accessed when the expression is evaluated in the specified environment. This ensures that the promise is evaluated at most once, and is why you only see “Calculating…” printed once in the following example.

double <- function(x) { 
  message("Calculating...")
  x * 2
}

h03 <- function(x) {
  c(x, x)
}

h03(double(x))
#> Calculating...
#> [1] 40 40


Thanks to lazy evaluation, default values can be defined in terms of other arguments, or even in terms of variables defined later in the function:

h04 <- function(x = 1, y = x * 2, z = a + b) {
  a <- 10
  b <- 100
  
  c(x, y, z)
}

h04()


Many base R functions use this technique, but I don’t recommend it. It makes the code harder to understand: to predict what will be returned, you need to know the exact order in which default arguments are evaluated.

The evaluation environment is slightly different for default and user supplied arguments, as default arguments are evaluated inside the function. This means that seemingly identical calls can yield different results. It’s easiest to see this with an extreme example:

h05 <- function(x = ls()) {
  a <- 1
  x
}

# ls() evaluated inside h05:
h05()
#> [1] "a" "x"

# ls() evaluated in global environment:
h05(ls())
#> [1] "h05"

To determine if an argument’s value comes from the user or from a default, you can use missing():


## Dot ...

There are two primary uses of ...

* If your function takes a function as an argument, you want some way to pass additional arguments to that function. In this example, lapply() uses ... to pass na.rm on to mean():

x <- list(c(1, 3, NA), c(4, NA, 6))
str(lapply(x, mean, na.rm = TRUE))
#> List of 2
#>  $ : num 2
#>  $ : num 5

* If your function is an S3 generic, you need some way to allow methods to take arbitrary extra arguments. For example, take the print() function. Because there are different options for printing depending on the type of object, there’s no way to pre-specify every possible argument and ... allows individual methods to have different arguments

# Environement

The environment is the data structure that powers scoping. Generally, an environment is similar to a named list, with four important exceptions:

    Every name must be unique.

    The names in an environment are not ordered.

    An environment has a parent.

    Environments are not copied when modified.

The job of an environment is to associate, or bind, a set of names to a set of values. You can think of an environment as a bag of names, with no implied order (i.e. it doesn’t make sense to ask which is the first element in an environment). For that reason, we’ll draw the environment as so:

![](./pics/01_environment.png)

unlike most R objects, when you modify them, you modify them in place, and don’t create a copy. One important implication is that environments can contain themselves.

```{r}
e1 <- rlang::env(
  a = FALSE,
  b = "a",
  c = 2.3,
  d = 1:3,
)
e1
rlang::env_print(e1)
names(e1)
```


The current environment, or current_env() is the environment in which code is currently executing. When you’re experimenting interactively, that’s usually the global environment, or global_env(). The global environment is sometimes called your “workspace”, as it’s where all interactive (i.e. outside of a function) computation takes place.

To compare environments, you need to use identical() and not ==. This is because == is a vectorised operator, and environments are not vectors.

```{r}
identical(globalenv(), environment())
```

Every environment has a parent, another environment. In diagrams, the parent is shown as a small pale blue circle and arrow that points to another environment. The parent is what’s used to implement lexical scoping: if a name is not found in an environment, then R will look in its parent (and so on).

```{r}
rlang::env_parent(e1)
parent.env(e1)
```

The ancestors of an environment have an important relationship to <<-. Regular assignment, <-, always creates a variable in the current environment. Super assignment, <<-, never creates a variable in the current environment, but instead modifies an existing variable found in a parent environment.

x <- 0
f <- function() {
  x <<- 1
}
f()
x

If <<- doesn’t find an existing variable, it will create one in the global environment. This is usually undesirable, because global variables introduce non-obvious dependencies between functions.

You can get and set elements of an environment with $ and [[ in the same way as a list:

e3 <- env(x = 1, y = 2)
e3$x
#> [1] 1
e3$z <- 3
e3[["z"]]

## Package environments and the search path

Each package attached by library() or require() becomes one of the parents of the global environment. The immediate parent of the global environment is the last package you attached31, the parent of that package is the second to last package you attached, …

Note the difference between attached and loaded. A package is loaded automatically if you access one of its functions using ::; it is only attached to the search path by library() or require()

![](./pics/02_searchPath.png)

If you follow all the parents back, you see the order in which every package has been attached. This is known as the search path because all objects in these environments can be found from the top-level interactive workspace. You can see the names of these environments with base::search()

```{r}
search()
library(rlang)
search()
detach("package:rlang")
```

Note that when you attach another package with library(), the parent environment of the global environment changes:

![](./pics/02_searchPath2.png)

The goal of namespaces is to make sure that this does not happen, and that every package works the same way regardless of what packages are attached by the user.

sd() is defined in terms of var(), so you might worry that the result of sd() would be affected by any function called var() either in the global environment, or in one of the other attached packages. R avoids this problem by taking advantage of the function versus binding environment described above. Every function in a package is associated with a pair of environments: the package environment, which you learned about earlier, and the namespace environment.

    The package environment is the external interface to the package. It’s how you, the R user, find a function in an attached package or with ::. Its parent is determined by search path, i.e. the order in which packages have been attached.

    The namespace environment is the internal interface to the package. The package environment controls how we find the function; the namespace controls how the function finds its variables.


Every namespace environment has the same set of ancestors:

    Each namespace has an imports environment that contains bindings to all the functions used by the package. The imports environment is controlled by the package developer with the NAMESPACE file.

    Explicitly importing every base function would be tiresome, so the parent of the imports environment is the base namespace. The base namespace contains the same bindings as the base environment, but it has a different parent.

    The parent of the base namespace is the global environment. This means that if a binding isn’t defined in the imports environment the package will look for it in the usual way. This is usually a bad idea (because it makes code depend on other loaded packages), so R CMD check automatically warns about such code. It is needed primarily for historical reasons, particularly due to how S3 method dispatch works.

## Function environments


Most environments are not created by you with new.env() but are created as a consequence of using functions. This section discusses the four types of environments associated with a function: enclosing, binding, execution, and calling.

The enclosing environment is the environment where the function was created. Every function has one and only one enclosing environment. For the three other types of environment, there may be 0, 1, or many environments associated with each function:

    Binding a function to a name with <- defines a binding environment.

    Calling a function creates an ephemeral execution environment that stores variables created during execution.

    Every execution environment is associated with a calling environment, which tells you where the function was called.

The enclosing environment belongs to the function, and never changes, even if the function is moved to a different environment. The enclosing environment determines how the function finds values; the binding environments determine how we find the function.

The distinction between the binding environment and the enclosing environment is important for package namespaces. Package namespaces keep packages independent. For example, if package A uses the base mean() function, what happens if package B creates its own mean() function? Namespaces ensure that package A continues to use the base mean() function, and that package A is not affected by package B (unless explicitly asked for). 

Namespaces are implemented using environments, taking advantage of the fact that functions don’t have to live in their enclosing environments. For example, take the base function sd(). Its binding and enclosing environments are different:

```{r}
environment(sd)
pryr::where("sd")
```

The definition of sd() uses var(), but if we make our own version of var() it doesn’t affect sd():

```{r}
sd
x <- seq_len(10)
sd(x)

var <- function(x) "I do something really different"
sd(x)
var(x)
```

This works because every package has two environments associated with it: the package environment and the namespace environment. The package environment contains every publicly accessible function, and is placed on the search path. The namespace environment contains all functions (including internal functions), and its parent environment is a special imports environment that contains bindings to all the functions that the package needs. Every exported function in a package is bound into the package environment, but enclosed by the namespace environment. This complicated relationship is illustrated by the following diagram:

![](./pics/03_path.png)


When we type var into the console, it’s found first in the global environment. When sd() looks for var() it finds it first in its namespace environment so never looks in the globalenv().

### Execution environments 

g <- function(x) {
  if (!exists("a", inherits = FALSE)) {
    message("Defining a")
    a <- 1
  } else {
    a <- a + 1
  }
  a
}
g(10)
g(10)

This function returns the same value every time it is called because of the fresh start principle, described in a fresh start. Each time a function is called, a new environment is created to host execution. The parent of the execution environment is the enclosing environment of the function. Once the function has completed, this environment is thrown away.


When you create a function inside another function, the enclosing environment of the child function is the execution environment of the parent, and the execution environment is no longer ephemeral.